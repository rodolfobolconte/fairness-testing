{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('../datasets/compas-propublica/compas-scores-two-years.csv')\n",
    "\n",
    "def preProcess(ds):\n",
    "    # drop duplicated feature columns\n",
    "    ds.drop(ds[['decile_score.1', 'screening_date', 'v_screening_date', 'priors_count.1']], axis=1, inplace=True)\n",
    "\n",
    "    # convert dates in string to date/time format\n",
    "    ds['compas_screening_date'] = pd.to_datetime(ds['compas_screening_date'])\n",
    "    ds['dob'] = pd.to_datetime(ds['dob'])\n",
    "    ds['c_jail_in'] = pd.to_datetime(ds['c_jail_in'])\n",
    "    ds['c_jail_out'] = pd.to_datetime(ds['c_jail_out'])\n",
    "    ds['c_offense_date'] = pd.to_datetime(ds['c_offense_date'])\n",
    "    ds['c_arrest_date'] = pd.to_datetime(ds['c_arrest_date'])\n",
    "    ds['r_offense_date'] = pd.to_datetime(ds['r_offense_date'])\n",
    "    ds['r_jail_in'] = pd.to_datetime(ds['r_jail_in'])\n",
    "    ds['r_jail_out'] = pd.to_datetime(ds['r_jail_out'])\n",
    "    ds['vr_offense_date'] = pd.to_datetime(ds['vr_offense_date'])\n",
    "    ds['in_custody'] = pd.to_datetime(ds['in_custody'])\n",
    "    ds['out_custody'] = pd.to_datetime(ds['out_custody'])\n",
    "    \n",
    "    # calculate the prison days\n",
    "    ds['prison_days'] = (ds['c_jail_out'] - ds['c_jail_in'])\n",
    "    ds['prison_days'] = [str(days).split()[0] for days in ds['prison_days']]\n",
    "    # calculate the custody days\n",
    "    ds['custody_days'] = (ds['out_custody'] - ds['in_custody'])\n",
    "    ds['custody_days'] = [str(days).split()[0] for days in ds['custody_days']]\n",
    "\n",
    "    # classificate medium and high score like highscore and convert to 0 and 1\n",
    "    ds['score_binary'] = np.where(ds['score_text'] != 'Low', 1, 0)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds = preProcess(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes de Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['vr_charge_desc'].value_counts().sort_values().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    if ds.loc[i]['priors_count'] != ds.loc[i]['priors_count.1']:\n",
    "        print(i, ds.loc[i]['priors_count'], ds.loc[i]['priors_count.1'])\n",
    "\n",
    "# for i in range(len(ds)):\n",
    "#     print(i, ds.loc[i]['is_recid'], ds.loc[i]['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for linha in ds.index:\n",
    "    if ds['c_jail_in'][linha] > ds['c_jail_out'][linha]:\n",
    "        print(linha, ds['c_jail_in'][linha], ds['c_jail_out'][linha])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção dos Atributos de Treino e Rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = ds[['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'days_b_screening_arrest', 'c_charge_degree', 'is_recid', 'r_charge_degree', 'r_days_from_arrest', 'is_violent_recid', 'vr_charge_degree', 'prison_days', 'custody_days']]\n",
    "\n",
    "data_y = ds['two_year_recid']\n",
    "\n",
    "prev_compas = ds['score_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão do Dataset para Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd70 = (len(data_x) * 70) // 100\n",
    "\n",
    "train_x = data_x.loc[:qtd70]\n",
    "train_y = data_y.loc[:qtd70]\n",
    "\n",
    "test_x = data_x.loc[qtd70:]\n",
    "test_y = data_y.loc[qtd70:]\n",
    "test_prev_compas = prev_compas.loc[qtd70:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e Execução de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\compas-tests\\dataset-fit-and-predict.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/a%3A/Downloads/Temporario/fairness-testing/compas-tests/dataset-fit-and-predict.ipynb#ch0000030?line=0'>1</a>\u001b[0m random_forest \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/a%3A/Downloads/Temporario/fairness-testing/compas-tests/dataset-fit-and-predict.ipynb#ch0000030?line=1'>2</a>\u001b[0m gradient_boost \u001b[39m=\u001b[39m GradientBoostingClassifier()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/a%3A/Downloads/Temporario/fairness-testing/compas-tests/dataset-fit-and-predict.ipynb#ch0000030?line=3'>4</a>\u001b[0m random_forest\u001b[39m.\u001b[39;49mfit(train_x, train_y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/a%3A/Downloads/Temporario/fairness-testing/compas-tests/dataset-fit-and-predict.ipynb#ch0000030?line=5'>6</a>\u001b[0m prevision \u001b[39m=\u001b[39m random_forest\u001b[39m.\u001b[39mpredict(test_x)\n",
      "File \u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:327\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=324'>325</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=325'>326</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=326'>327</a>\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=327'>328</a>\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=328'>329</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=329'>330</a>\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/ensemble/_forest.py?line=330'>331</a>\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\env\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/base.py?line=578'>579</a>\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/base.py?line=579'>580</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/base.py?line=580'>581</a>\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=960'>961</a>\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=961'>962</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=963'>964</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=964'>965</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=965'>966</a>\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=966'>967</a>\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=967'>968</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=968'>969</a>\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=969'>970</a>\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=970'>971</a>\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=971'>972</a>\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=972'>973</a>\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=973'>974</a>\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=974'>975</a>\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=975'>976</a>\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=976'>977</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=978'>979</a>\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=980'>981</a>\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=743'>744</a>\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=744'>745</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=745'>746</a>\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=746'>747</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=747'>748</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=748'>749</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/sklearn/utils/validation.py?line=749'>750</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32ma:\\Downloads\\Temporario\\fairness-testing\\env\\lib\\site-packages\\pandas\\core\\generic.py:2072\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/pandas/core/generic.py?line=2070'>2071</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> <a href='file:///a%3A/Downloads/Temporario/fairness-testing/env/lib/site-packages/pandas/core/generic.py?line=2071'>2072</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "\n",
    "random_forest.fit(train_x, train_y)\n",
    "\n",
    "prevision = random_forest.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------- ANTIGO ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento do Dataset\n",
    "\n",
    "Utilizando [função](https://docs.responsibly.ai/_modules/responsibly/dataset/compas.html#COMPASDataset) de pré-processamento do pacote responsibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load of the dataset\n",
    "#ds = pd.read_csv(\"../datasets/compas/cox-violent-parsed.csv\")\n",
    "\n",
    "# export the dataset to csv file\n",
    "#ds.to_csv('dataset.csv', index=False, encoding='utf8')\n",
    "\n",
    "def preProcess(ds):\n",
    "    # filter row of:\n",
    "    # screening arrest between and -30 and 30\n",
    "    # without recid information (-1)\n",
    "    # charge degree other than O\n",
    "    # score text not empty\n",
    "    ds = ds[(ds['days_b_screening_arrest'] <= 30) & (ds['days_b_screening_arrest'] >= -30) & (ds['is_recid'] != -1) & (ds['c_charge_degree'] != 'O') & (ds['score_text'] != 'N/A')]\n",
    "\n",
    "    # convert values of jail in and jail out to date/time format\n",
    "    ds['c_jail_out'] = pd.to_datetime(ds['c_jail_out'])\n",
    "    ds['c_jail_in'] = pd.to_datetime(ds['c_jail_in'])\n",
    "    # calculate the prison days\n",
    "    ds['length_of_stay'] = (ds['c_jail_out'] - ds['c_jail_in'])\n",
    "\n",
    "    # classificate medium and high score like highscore\n",
    "    ds['score_factor'] = np.where(ds['score_text'] != 'Low', 'HighScore', 'LowScore')\n",
    "    # create the prediction values, highscore is 1 and lowscore is 0\n",
    "    ds['y_pred'] = (ds['score_factor'] == 'HighScore')\n",
    "\n",
    "    return ds\n",
    "\n",
    "#ds = preProcess(ds)\n",
    "\n",
    "# export the dataset pre processed to csv file\n",
    "#ds.to_csv('dataset-pre-processed.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento do Dataset Pré-Processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"dataset-pre-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform negative days in positive values of lenght_of_stay feature\n",
    "ds['length_of_stay_pp'] = [int(a.split()[0]) * -1 if int(a.split()[0]) < 0 else int(a.split()[0]) for a in ds['length_of_stay']]\n",
    "\n",
    "#drop features not importants to prediction\n",
    "#ds.drop(ds[['id', 'name', 'first', 'last', 'compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out', 'c_case_number', 'c_offense_date', 'c_arrest_date', 'is_recid', 'r_case_number', 'r_offense_date', 'r_jail_in', 'r_jail_out', 'violent_recid', 'vr_case_number', 'vr_offense_date', 'type_of_assessment', 'decile_score.1', 'score_text', 'screening_date', 'v_type_of_assessment', 'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1', 'y_pred']], axis=1, inplace=True)\n",
    "\n",
    "# data features to train and test models\n",
    "data_x = ds[['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'days_b_screening_arrest', 'c_charge_degree', 'length_of_stay']]\n",
    "\n",
    "label = ds['is_recid']\n",
    "prev = ds['y_pred']\n",
    "\n",
    "# interessante fazer um tratamento das datas de custódia, calcular os dias talvez\n",
    "# tratar a coluna length_of_stay\n",
    "# fazer tratamento de linhas repetidas para o mesmo detento, diferencia apenas as datas de custódia, pode ser possível filtrar utilizando o nome e a data de ocorrência do crime, já que existem mais de um crime para determinadas pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linha in ds.index:\n",
    "#     if ds['c_jail_in'][linha] > ds['c_jail_out'][linha]:\n",
    "#         print(linha, ds['c_jail_in'][linha], ds['c_jail_out'][linha])\n",
    "\n",
    "for linha in ds.index:\n",
    "    print(ds['name'][linha])\n",
    "\n",
    "# print(ds[['c_jail_in', 'c_jail_out', 'length_of_stay']].loc[792])\n",
    "\n",
    "\n",
    "# print(ds['length_of_stay_pp'])\n",
    "# print(ds['length_of_stay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['name'].value_counts().sort_values().to_string())\n",
    "\n",
    "# for i in range(len(ds)):\n",
    "#     if str(ds.loc[i]['violent_recid']) != 'nan':\n",
    "#         print(i, ds.loc[i]['violent_recid'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e859d2b2c5ec404c80be3ae1107f381ab65c60291df144b2c8070f47769fe782"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
