{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('../datasets/compas-propublica/compas-scores-two-years.csv')\n",
    "\n",
    "def preProcess(ds):\n",
    "    # select African-American and Caucasian people\n",
    "    ds = ds[(ds['race'] == 'African-American') | (ds['race'] == 'Caucasian')]\n",
    "    \n",
    "    # drop duplicated feature columns\n",
    "    ds.drop(ds[['decile_score.1', 'screening_date', 'v_screening_date', 'priors_count.1']], axis=1, inplace=True)\n",
    "\n",
    "    # convert dates in string to date/time format\n",
    "    ds['compas_screening_date'] = pd.to_datetime(ds['compas_screening_date'])\n",
    "    ds['dob'] = pd.to_datetime(ds['dob'])\n",
    "    ds['c_jail_in'] = pd.to_datetime(ds['c_jail_in'])\n",
    "    ds['c_jail_out'] = pd.to_datetime(ds['c_jail_out'])\n",
    "    ds['c_offense_date'] = pd.to_datetime(ds['c_offense_date'])\n",
    "    ds['c_arrest_date'] = pd.to_datetime(ds['c_arrest_date'])\n",
    "    ds['r_offense_date'] = pd.to_datetime(ds['r_offense_date'])\n",
    "    ds['r_jail_in'] = pd.to_datetime(ds['r_jail_in'])\n",
    "    ds['r_jail_out'] = pd.to_datetime(ds['r_jail_out'])\n",
    "    ds['vr_offense_date'] = pd.to_datetime(ds['vr_offense_date'])\n",
    "    ds['in_custody'] = pd.to_datetime(ds['in_custody'])\n",
    "    ds['out_custody'] = pd.to_datetime(ds['out_custody'])\n",
    "\n",
    "    # converting sex categorical variable in numeric variable\n",
    "    sex = {'Female':1, 'Male':2}\n",
    "    ds['sex'] = ds['sex'].map(sex)\n",
    "    # converting race categorical variable in numeric variable\n",
    "    race = {'African-American':1, 'Caucasian':2}\n",
    "    ds['race'] = ds['race'].map(race)\n",
    "    # converting c_charge_degree categorical variable in numeric variable\n",
    "    c_charge_degree = {'F':1, 'M':2}\n",
    "    ds['c_charge_degree'] = ds['c_charge_degree'].map(c_charge_degree)\n",
    "    # converting r_charge_degree and vr_charge_degree categorical variables in numeric variables\n",
    "    r_vr_charge_degree = {np.nan:0, '(CO3)':1, '(F1)':2, '(F2)':3, '(F3)':4, '(F5)':5, '(F6)':6, '(F7)':7, '(M1)':8, '(M2)':9, '(MO3)':10}\n",
    "    ds['r_charge_degree'] = ds['r_charge_degree'].map(r_vr_charge_degree)\n",
    "    ds['vr_charge_degree'] = ds['vr_charge_degree'].map(r_vr_charge_degree)\n",
    "\n",
    "    # replace nan values in number 1000\n",
    "    ds['days_b_screening_arrest'] = [1000 if np.isnan(days) else days for days in ds['days_b_screening_arrest']]\n",
    "    ds['r_days_from_arrest'] = [1000 if np.isnan(days) else days for days in ds['r_days_from_arrest']]\n",
    "\n",
    "    # calculate the prison days and turns into int values type\n",
    "    ds['prison_days'] = (ds['c_jail_out'] - ds['c_jail_in'])\n",
    "    ds['prison_days'] = [str(days).split()[0] for days in ds['prison_days']]\n",
    "    ds['prison_days'] = [1000 if days=='NaT' else int(days) for days in ds['prison_days']]\n",
    "    ds['prison_days'] = pd.to_numeric(ds['prison_days'])\n",
    "\n",
    "    # calculate the custody days and turns into int values type\n",
    "    ds['custody_days'] = (ds['out_custody'] - ds['in_custody'])\n",
    "    ds['custody_days'] = [str(days).split()[0] for days in ds['custody_days']]\n",
    "    ds['custody_days'] = [1000 if days=='NaT' else int(days) for days in ds['custody_days']]\n",
    "    ds['custody_days'] = pd.to_numeric(ds['custody_days'])\n",
    "\n",
    "    # classificate medium and high score like highscore and convert to 0 and 1\n",
    "    ds['score_binary'] = np.where(ds['score_text'] != 'Low', 1, 0)\n",
    "\n",
    "    return ds\n",
    "\n",
    "ds = preProcess(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes de Visualizações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variaveis categoricas: 'sex', 'race', 'c_charge_degree', 'r_charge_degree', 'vr_charge_degree'\n",
    "\n",
    "#print(ds['race'].value_counts().to_string())\n",
    "#print(ds['days_b_screening_arrest'].value_counts().sort_values())\n",
    "\n",
    "#print(ds['r_days_from_arrest'].isna().sum())\n",
    "\n",
    "#print(ds[(ds['race'] == 1) | (ds['race'] == 3)]['race'].value_counts())\n",
    "\n",
    "#print(ds.dtypes)\n",
    "\n",
    "#print(ds['days_b_screening_arrest'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ds)):\n",
    "#     if ds.loc[i]['priors_count'] != ds.loc[i]['priors_count.1']:\n",
    "#         print(i, ds.loc[i]['priors_count'], ds.loc[i]['priors_count.1'])\n",
    "\n",
    "# for i in range(len(ds)):\n",
    "#     print(i, ds.loc[i]['is_recid'], ds.loc[i]['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for linha in ds.index:\n",
    "#     if ds['c_jail_in'][linha] > ds['c_jail_out'][linha]:\n",
    "#         print(linha, ds['c_jail_in'][linha], ds['c_jail_out'][linha])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção dos Atributos de Treino e Rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = ds[['sex', 'age', 'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'days_b_screening_arrest', 'c_charge_degree', 'is_recid', 'r_charge_degree', 'r_days_from_arrest', 'is_violent_recid', 'vr_charge_degree', 'prison_days', 'custody_days']]\n",
    "\n",
    "data_y = ds['two_year_recid']\n",
    "\n",
    "prev_compas = ds['score_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão do Dataset para Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd70 = (len(data_x) * 70) // 100\n",
    "\n",
    "train_x = data_x.loc[:qtd70]\n",
    "train_y = data_y.loc[:qtd70]\n",
    "\n",
    "test_x = data_x.loc[qtd70:]\n",
    "test_y = data_y.loc[qtd70:]\n",
    "test_prev_compas = prev_compas.loc[qtd70:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e Execução de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "gradient_boost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.fit(train_x, train_y)\n",
    "gradient_boost.fit(train_x, train_y)\n",
    "\n",
    "prev_random_forest = random_forest.predict(test_x)\n",
    "prev_gradient_boost = gradient_boost.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Random Forest =======\n",
      "Accuracy: 0.9661\n",
      "Precision: 0.9330\n",
      "Recall: 1.0000\n",
      "Confusion Matrix: \n",
      "[[1222   84]\n",
      " [   0 1169]]\n",
      "\n",
      "======= Gradient Boosting =======\n",
      "Accuracy: 0.9653\n",
      "Precision: 0.9329\n",
      "Recall: 0.9983\n",
      "Confusion Matrix: \n",
      "[[1222   84]\n",
      " [   2 1167]]\n"
     ]
    }
   ],
   "source": [
    "print('======= Random Forest with True Values =======')\n",
    "print(f'Accuracy: {accuracy_score(test_y, prev_random_forest):.4f}')\n",
    "print(f'Precision: {precision_score(test_y, prev_random_forest):.4f}')\n",
    "print(f'Recall: {recall_score(test_y, prev_random_forest):.4f}')\n",
    "#TN[0][0], FN[1][0], TP[1][1], FP[0][1]\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(test_y, prev_random_forest)}')\n",
    "\n",
    "print('\\n======= Gradient Boosting with True Values =======')\n",
    "print(f'Accuracy: {accuracy_score(test_y, prev_gradient_boost):.4f}')\n",
    "print(f'Precision: {precision_score(test_y, prev_gradient_boost):.4f}')\n",
    "print(f'Recall: {recall_score(test_y, prev_gradient_boost):.4f}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(test_y, prev_gradient_boost)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Random Forest with COMPAS Prevision =======\n",
      "Accuracy: 0.6396\n",
      "Precision: 0.6464\n",
      "Recall: 0.6434\n",
      "Confusion Matrix: \n",
      "[[773 443]\n",
      " [449 810]]\n",
      "\n",
      "======= Gradient Boosting with COMPAS Prevision =======\n",
      "Accuracy: 0.6388\n",
      "Precision: 0.6459\n",
      "Recall: 0.6418\n",
      "Confusion Matrix: \n",
      "[[773 443]\n",
      " [451 808]]\n"
     ]
    }
   ],
   "source": [
    "print('======= Random Forest with COMPAS Prevision =======')\n",
    "print(f'Accuracy: {accuracy_score(test_prev_compas, prev_random_forest):.4f}')\n",
    "print(f'Precision: {precision_score(test_prev_compas, prev_random_forest):.4f}')\n",
    "print(f'Recall: {recall_score(test_prev_compas, prev_random_forest):.4f}')\n",
    "#TN[0][0], FN[1][0], TP[1][1], FP[0][1]\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(test_prev_compas, prev_random_forest)}')\n",
    "\n",
    "print('\\n======= Gradient Boosting with COMPAS Prevision =======')\n",
    "print(f'Accuracy: {accuracy_score(test_prev_compas, prev_gradient_boost):.4f}')\n",
    "print(f'Precision: {precision_score(test_prev_compas, prev_gradient_boost):.4f}')\n",
    "print(f'Recall: {recall_score(test_prev_compas, prev_gradient_boost):.4f}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(test_prev_compas, prev_gradient_boost)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------- ANTIGO ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento do Dataset\n",
    "\n",
    "Utilizando [função](https://docs.responsibly.ai/_modules/responsibly/dataset/compas.html#COMPASDataset) de pré-processamento do pacote responsibly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load of the dataset\n",
    "# #ds = pd.read_csv(\"../datasets/compas/cox-violent-parsed.csv\")\n",
    "\n",
    "# # export the dataset to csv file\n",
    "# #ds.to_csv('dataset.csv', index=False, encoding='utf8')\n",
    "\n",
    "# def preProcess(ds):\n",
    "#     # filter row of:\n",
    "#     # screening arrest between and -30 and 30\n",
    "#     # without recid information (-1)\n",
    "#     # charge degree other than O\n",
    "#     # score text not empty\n",
    "#     ds = ds[(ds['days_b_screening_arrest'] <= 30) & (ds['days_b_screening_arrest'] >= -30) & (ds['is_recid'] != -1) & (ds['c_charge_degree'] != 'O') & (ds['score_text'] != 'N/A')]\n",
    "\n",
    "#     # convert values of jail in and jail out to date/time format\n",
    "#     ds['c_jail_out'] = pd.to_datetime(ds['c_jail_out'])\n",
    "#     ds['c_jail_in'] = pd.to_datetime(ds['c_jail_in'])\n",
    "#     # calculate the prison days\n",
    "#     ds['length_of_stay'] = (ds['c_jail_out'] - ds['c_jail_in'])\n",
    "\n",
    "#     # classificate medium and high score like highscore\n",
    "#     ds['score_factor'] = np.where(ds['score_text'] != 'Low', 'HighScore', 'LowScore')\n",
    "#     # create the prediction values, highscore is 1 and lowscore is 0\n",
    "#     ds['y_pred'] = (ds['score_factor'] == 'HighScore')\n",
    "\n",
    "#     return ds\n",
    "\n",
    "# #ds = preProcess(ds)\n",
    "\n",
    "# # export the dataset pre processed to csv file\n",
    "# #ds.to_csv('dataset-pre-processed.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento do Dataset Pré-Processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = pd.read_csv(\"dataset-pre-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # transform negative days in positive values of lenght_of_stay feature\n",
    "# ds['length_of_stay_pp'] = [int(a.split()[0]) * -1 if int(a.split()[0]) < 0 else int(a.split()[0]) for a in ds['length_of_stay']]\n",
    "\n",
    "# #drop features not importants to prediction\n",
    "# #ds.drop(ds[['id', 'name', 'first', 'last', 'compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out', 'c_case_number', 'c_offense_date', 'c_arrest_date', 'is_recid', 'r_case_number', 'r_offense_date', 'r_jail_in', 'r_jail_out', 'violent_recid', 'vr_case_number', 'vr_offense_date', 'type_of_assessment', 'decile_score.1', 'score_text', 'screening_date', 'v_type_of_assessment', 'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1', 'y_pred']], axis=1, inplace=True)\n",
    "\n",
    "# # data features to train and test models\n",
    "# data_x = ds[['sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'days_b_screening_arrest', 'c_charge_degree', 'length_of_stay']]\n",
    "\n",
    "# label = ds['is_recid']\n",
    "# prev = ds['y_pred']\n",
    "\n",
    "# # interessante fazer um tratamento das datas de custódia, calcular os dias talvez\n",
    "# # tratar a coluna length_of_stay\n",
    "# # fazer tratamento de linhas repetidas para o mesmo detento, diferencia apenas as datas de custódia, pode ser possível filtrar utilizando o nome e a data de ocorrência do crime, já que existem mais de um crime para determinadas pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for linha in ds.index:\n",
    "# #     if ds['c_jail_in'][linha] > ds['c_jail_out'][linha]:\n",
    "# #         print(linha, ds['c_jail_in'][linha], ds['c_jail_out'][linha])\n",
    "\n",
    "# for linha in ds.index:\n",
    "#     print(ds['name'][linha])\n",
    "\n",
    "# # print(ds[['c_jail_in', 'c_jail_out', 'length_of_stay']].loc[792])\n",
    "\n",
    "\n",
    "# # print(ds['length_of_stay_pp'])\n",
    "# # print(ds['length_of_stay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ds['name'].value_counts().sort_values().to_string())\n",
    "\n",
    "# # for i in range(len(ds)):\n",
    "# #     if str(ds.loc[i]['violent_recid']) != 'nan':\n",
    "# #         print(i, ds.loc[i]['violent_recid'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e859d2b2c5ec404c80be3ae1107f381ab65c60291df144b2c8070f47769fe782"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
